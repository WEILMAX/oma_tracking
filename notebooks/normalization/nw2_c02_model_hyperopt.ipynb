{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import datetime\n",
    "import pandas as pd\n",
    "from pytz import utc\n",
    "import os\n",
    "import mlflow\n",
    "import numpy as np\n",
    "\n",
    "# mlflow imports\n",
    "from mlflow.models.signature import infer_signature\n",
    "\n",
    "# sklearn imports\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "# xgboost imports\n",
    "from xgboost import XGBRegressor\n",
    "\n",
    "# hyperopt imports\n",
    "from hyperopt import hp,fmin,tpe,STATUS_OK,Trials\n",
    "\n",
    "# oma_tracking imports\n",
    "from oma_tracking.data.utils import read_simulations_csv_files\n",
    "from oma_tracking.data import make_dataset\n",
    "from oma_tracking.data.preprocessing import AngleTransformer, sin_cos_angle_inputs\n",
    "import oma_tracking.models.mlflow_functions as mlflow_f\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "start =  datetime.datetime(2022,11,1,tzinfo=utc)\n",
    "stop  = datetime.datetime(2023,3,1,tzinfo=utc)\n",
    "location = 'nw2c02'\n",
    "name_location = 'NW2_C02'\n",
    "\n",
    "# Data Paths\n",
    "data_file_name = '_'.join([location, start.strftime(\"%Y%m%d\"), stop.strftime(\"%Y%m%d\")])\n",
    "data_path = \"../../data/nw2/raw/\" + data_file_name + \".parquet\"\n",
    "mvbc_path = \"../../data/nw2/mvbc_data.parquet\"\n",
    "tracked_frequencies_path = \"../../data/nw2/tracked_modes/\" + location + \".parquet\"\n",
    "simulations_data_path = \"../../data/nw2/simulations/\" + location + \"/\"\n",
    "\n",
    "# Get all the data\n",
    "data = pd.read_parquet(data_path)\n",
    "mvbc_data = pd.read_parquet(mvbc_path)\n",
    "tracked_frequencies = pd.read_parquet(tracked_frequencies_path)\n",
    "#simulation_data = read_simulations_csv_files(simulations_data_path + \"eigen_frequencies/\")\n",
    "#simulation_shifts = read_simulations_csv_files(simulations_data_path + \"mean_shifts/\")\n",
    "#simulation_errors = pd.read_csv(simulations_data_path + \"errors/Errors_No_scour.csv\", index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\max\\documents\\owi_lab\\code\\packages\\oma_tracking\\oma_tracking\\models\\mlflow_functions.py:124: UserWarning: Mlflow_tracking_uri passed without checking checking username for ':' and '@' symbols. Manually control the uri!\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mlflow experiment set to: NW2_scour\n"
     ]
    }
   ],
   "source": [
    "AZURE_STORAGE_ACCESS_KEY = os.getenv('AZURE_STORAGE_ACCESS_KEY')\n",
    "AZURE_STORAGE_CONNECTION_STRING = os.getenv('AZURE_STORAGE_CONNECTION_STRING')\n",
    "MLFLOW_TRACKING_URI = os.getenv('MLFLOW_TRACKING_URI')\n",
    "\n",
    "mlflow.set_tracking_uri(MLFLOW_TRACKING_URI)\n",
    "\n",
    "artifact_root = 'wasbs://test@mlflowstoragev1.blob.core.windows.net'\n",
    "mlflow_ui_string = mlflow_f.create_mlflow_ui(MLFLOW_TRACKING_URI, artifact_root)\n",
    "database_url = 'http://127.0.0.1:5000'\n",
    "mlflow_f.connect_mlflow_ui(mlflow_ui_string, database_url)\n",
    "\n",
    "experiment_name = 'NW2_scour'\n",
    "experiment = mlflow_f.run_mlflow_experiment(experiment_name = experiment_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "weather_inputs = make_dataset.get_weather_subset(mvbc_data)\n",
    "scada_inputs = make_dataset.get_scada_subset(data)\n",
    "\n",
    "inputs = pd.concat([\n",
    "            weather_inputs,\n",
    "            scada_inputs\n",
    "        ],axis=1)\n",
    "\n",
    "prediction_params = tracked_frequencies "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "hyperopt_folder = \"../../data/nw2/model_hyperopt/\" + location + \"_\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100%|██████████| 200/200 [24:50<00:00,  7.45s/trial, best loss: -0.20437119789601885]\n",
      "{'colsample_bytree': 0.5041176658380875, 'learning_rate': 0.0253010280465614, 'max_depth': 7.0, 'n_estimators': 331.0}\n",
      "100%|██████████| 200/200 [33:26<00:00, 10.03s/trial, best loss: -0.7403128766032342]\n",
      "{'colsample_bytree': 0.7509143903507746, 'learning_rate': 0.03354811107736168, 'max_depth': 12.0, 'n_estimators': 459.0}\n",
      "100%|██████████| 200/200 [29:07<00:00,  8.74s/trial, best loss: -0.42533298606718917]\n",
      "{'colsample_bytree': 0.5235919674086554, 'learning_rate': 0.0435470685765176, 'max_depth': 13.0, 'n_estimators': 234.0}\n",
      "100%|██████████| 200/200 [51:53<00:00, 15.57s/trial, best loss: -0.6736309360396051] \n",
      "{'colsample_bytree': 0.6333742869249575, 'learning_rate': 0.02959759563450521, 'max_depth': 10.0, 'n_estimators': 332.0}\n"
     ]
    }
   ],
   "source": [
    "seed = 2\n",
    "def objective_xgb(space):\n",
    "    model = Pipeline(\n",
    "            steps=[\n",
    "                ('preprocessing_angles', AngleTransformer(angles = ['winddirection', 'yaw'])),\n",
    "                ('regressor', XGBRegressor(\n",
    "                                 n_estimators = space['n_estimators'],\n",
    "                                 max_depth = space['max_depth'],\n",
    "                                 learning_rate = space['learning_rate'],\n",
    "                                 colsample_bytree = space['colsample_bytree'],\n",
    "                                 )\n",
    "                )\n",
    "            ]\n",
    "        )\n",
    "    score = cross_val_score(model,  X_train, y_train, cv=5, scoring='r2').mean()\n",
    "    # We aim to maximize r2 score, therefore we return it as a negative value\n",
    "    return {'loss': -score, 'status': STATUS_OK }\n",
    "def optimize_xgb(trial):\n",
    "    space = {\n",
    "        'n_estimators':hp.uniformint('n_estimators',10,500),\n",
    "        'max_depth':hp.uniformint('max_depth',3,20),\n",
    "        'learning_rate':hp.uniform('learning_rate',0.01,0.5),\n",
    "        'colsample_bytree': hp.uniform('colsample_bytree',0.1, 1),\n",
    "    }\n",
    "    best = \\\n",
    "        fmin(\n",
    "            fn = objective_xgb,\n",
    "            space = space,\n",
    "            algo = tpe.suggest,\n",
    "            trials = trial,\n",
    "            max_evals = 200,\n",
    "            rstate = np.random.default_rng(seed)\n",
    "            )\n",
    "    return best\n",
    "\n",
    "XGB_optimizations = {}\n",
    "for mode in prediction_params.columns:\n",
    "    y = prediction_params[mode].loc[inputs.index[0]:inputs.index[-1]].dropna()\n",
    "    X = inputs.loc[y.index].dropna()\n",
    "    y = y.loc[X.index]\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=seed)\n",
    "    X_train_val, X_val, y_train_val, y_val = train_test_split(X_train, y_train, test_size=0.2, random_state=seed)\n",
    "    trial2=Trials()\n",
    "    XGB_optimizations[mode]=optimize_xgb(trial2)\n",
    "    print(XGB_optimizations[mode])\n",
    "pd.DataFrame(XGB_optimizations).to_csv(hyperopt_folder + \"xgb_optimizations.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<hyperopt.base.Trials at 0x16e84f825e0>"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trial2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100%|██████████| 100/100 [2:31:42<00:00, 91.03s/trial, best loss: -0.22695911690307477] \n",
      "{'max_depth': 10.0, 'min_samples_leaf': 5.0, 'min_samples_split': 6.0, 'n_estimators': 439.0}\n",
      "100%|██████████| 100/100 [2:30:53<00:00, 90.54s/trial, best loss: -0.7317887866598072]  \n",
      "{'max_depth': 20.0, 'min_samples_leaf': 1.0, 'min_samples_split': 3.0, 'n_estimators': 459.0}\n",
      "100%|██████████| 100/100 [3:01:48<00:00, 109.08s/trial, best loss: -0.4318561033908006]  \n",
      "{'max_depth': 15.0, 'min_samples_leaf': 1.0, 'min_samples_split': 2.0, 'n_estimators': 233.0}\n",
      "100%|██████████| 100/100 [3:42:40<00:00, 133.60s/trial, best loss: -0.6592766620871874] \n",
      "{'max_depth': 13.0, 'min_samples_leaf': 3.0, 'min_samples_split': 2.0, 'n_estimators': 452.0}\n"
     ]
    }
   ],
   "source": [
    "from hyperopt import hp,fmin,tpe,STATUS_OK,Trials\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.model_selection import cross_val_score\n",
    "seed = 2\n",
    "\n",
    "def objective_rf(space):\n",
    "    model = Pipeline(\n",
    "            steps=[\n",
    "                ('preprocessing_angles', AngleTransformer(angles = ['winddirection', 'yaw'])),\n",
    "                ('regressor', RandomForestRegressor(\n",
    "                                 n_estimators = space['n_estimators'],\n",
    "                                 max_depth = space['max_depth'],\n",
    "                                 min_samples_leaf = space['min_samples_leaf'],\n",
    "                                 min_samples_split = space['min_samples_split']\n",
    "                                 )\n",
    "            )\n",
    "        ]\n",
    "    )\n",
    "    score = cross_val_score(model,  X_train, y_train, cv=5, scoring='r2').mean()\n",
    "    # We aim to maximize r2 score, therefore we return it as a negative value\n",
    "    return {'loss': -score, 'status': STATUS_OK }\n",
    "\n",
    "def optimize_rf(trial):\n",
    "    space = {\n",
    "        'n_estimators': hp.uniformint('n_estimators',10,500),\n",
    "        'max_depth': hp.uniformint('max_depth',3,20),\n",
    "        'min_samples_leaf': hp.uniformint('min_samples_leaf',1,5),\n",
    "        'min_samples_split': hp.uniformint('min_samples_split',2,6)\n",
    "    }\n",
    "    best = \\\n",
    "        fmin(\n",
    "            fn = objective_rf,\n",
    "            space = space,\n",
    "            algo = tpe.suggest,\n",
    "            trials = trial,\n",
    "            max_evals = 100,\n",
    "            rstate = np.random.default_rng(seed)\n",
    "            )\n",
    "    return best\n",
    "\n",
    "RF_optimizations = {}\n",
    "for mode in prediction_params.columns:\n",
    "    y = prediction_params[mode].loc[inputs.index[0]:inputs.index[-1]].dropna()\n",
    "    X = inputs.loc[y.index].dropna()\n",
    "    y = y.loc[X.index]\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=seed)\n",
    "    trial=Trials()\n",
    "    RF_optimizations[mode]=optimize_rf(trial)\n",
    "    print(RF_optimizations[mode])\n",
    "pd.DataFrame(RF_optimizations).to_csv(hyperopt_folder + \"rf_optimizations.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<hyperopt.base.Trials at 0x16e84f27f10>"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trial"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "soiltwin",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

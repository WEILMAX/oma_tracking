{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import datetime\n",
    "import pandas as pd\n",
    "from pytz import utc\n",
    "import os\n",
    "import mlflow\n",
    "import numpy as np\n",
    "\n",
    "# mlflow imports\n",
    "from mlflow.models.signature import infer_signature\n",
    "\n",
    "# sklearn imports\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "# xgboost imports\n",
    "from xgboost import XGBRegressor\n",
    "\n",
    "# hyperopt imports\n",
    "from hyperopt import hp,fmin,tpe,STATUS_OK,Trials\n",
    "\n",
    "# oma_tracking imports\n",
    "from oma_tracking.data.utils import read_simulations_csv_files\n",
    "from oma_tracking.data import make_dataset\n",
    "from oma_tracking.data.preprocessing import AngleTransformer, sin_cos_angle_inputs\n",
    "import oma_tracking.models.mlflow_functions as mlflow_f\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "start =  datetime.datetime(2022,11,1,tzinfo=utc)\n",
    "stop  = datetime.datetime(2023,3,1,tzinfo=utc)\n",
    "location = 'nw2d01'\n",
    "name_location = 'NW2_D01'\n",
    "\n",
    "# Data Paths\n",
    "data_path = \"../../data/nw2/raw/nw2d01_\" + start.strftime(\"%Y%m%d\") + \"_\" + stop.strftime(\"%Y%m%d\") + \".parquet\"\n",
    "mvbc_path = \"../../data/nw2/mvbc_data.parquet\"\n",
    "tracked_frequencies_path = \"../../data/nw2/tracked_modes/\" + location + \".parquet\"\n",
    "simulations_data_path = \"../../data/nw2/simulations/\" + location + \"/\"\n",
    "\n",
    "# Get all the data\n",
    "data = pd.read_parquet(data_path)\n",
    "mvbc_data = pd.read_parquet(mvbc_path)\n",
    "tracked_frequencies = pd.read_parquet(tracked_frequencies_path)\n",
    "simulation_data = read_simulations_csv_files(simulations_data_path + \"eigen_frequencies/\")\n",
    "simulation_shifts = read_simulations_csv_files(simulations_data_path + \"mean_shifts/\")\n",
    "simulation_errors = pd.read_csv(simulations_data_path + \"errors/Errors_No_scour.csv\", index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\max\\documents\\owi_lab\\code\\packages\\oma_tracking\\oma_tracking\\models\\mlflow_functions.py:124: UserWarning: Mlflow_tracking_uri passed without checking checking username for ':' and '@' symbols. Manually control the uri!\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mlflow experiment set to: NW2_scour\n"
     ]
    }
   ],
   "source": [
    "AZURE_STORAGE_ACCESS_KEY = os.getenv('AZURE_STORAGE_ACCESS_KEY')\n",
    "AZURE_STORAGE_CONNECTION_STRING = os.getenv('AZURE_STORAGE_CONNECTION_STRING')\n",
    "MLFLOW_TRACKING_URI = os.getenv('MLFLOW_TRACKING_URI')\n",
    "\n",
    "mlflow.set_tracking_uri(MLFLOW_TRACKING_URI)\n",
    "\n",
    "artifact_root = 'wasbs://test@mlflowstoragev1.blob.core.windows.net'\n",
    "mlflow_ui_string = mlflow_f.create_mlflow_ui(MLFLOW_TRACKING_URI, artifact_root)\n",
    "database_url = 'http://127.0.0.1:5000'\n",
    "mlflow_f.connect_mlflow_ui(mlflow_ui_string, database_url)\n",
    "\n",
    "experiment_name = 'NW2_scour'\n",
    "experiment = mlflow_f.run_mlflow_experiment(experiment_name = experiment_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "weather_inputs = make_dataset.get_weather_subset(mvbc_data)\n",
    "scada_inputs = make_dataset.get_scada_subset(data)\n",
    "\n",
    "inputs = pd.concat([\n",
    "            weather_inputs,\n",
    "            scada_inputs\n",
    "        ],axis=1)\n",
    "\n",
    "prediction_params = tracked_frequencies "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "hyperopt_folder = \"../../data/nw2/model_hyperopt/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100%|██████████| 100/100 [14:12<00:00,  8.52s/trial, best loss: -0.28305908969794374]\n",
      "{'colsample_bytree': 0.5249699361570449, 'learning_rate': 0.028744322686588067, 'max_depth': 6.0, 'n_estimators': 275.0}\n",
      "100%|██████████| 100/100 [18:22<00:00, 11.02s/trial, best loss: -0.5329579667688771]\n",
      "{'colsample_bytree': 0.5721606076901463, 'learning_rate': 0.04318642094053245, 'max_depth': 5.0, 'n_estimators': 353.0}\n",
      "100%|██████████| 100/100 [11:36<00:00,  6.97s/trial, best loss: -0.3643565778093386]\n",
      "{'colsample_bytree': 0.4637221837935779, 'learning_rate': 0.023786773494742574, 'max_depth': 10.0, 'n_estimators': 392.0}\n",
      "100%|██████████| 100/100 [09:56<00:00,  5.97s/trial, best loss: -0.5417091611145215]\n",
      "{'colsample_bytree': 0.5257177720137283, 'learning_rate': 0.06075855570180731, 'max_depth': 6.0, 'n_estimators': 242.0}\n"
     ]
    }
   ],
   "source": [
    "seed = 2\n",
    "def objective_xgb(space):\n",
    "    model = Pipeline(\n",
    "            steps=[\n",
    "                ('preprocessing_angles', AngleTransformer(angles = ['winddirection', 'yaw'])),\n",
    "                ('regressor', XGBRegressor(\n",
    "                                 n_estimators = space['n_estimators'],\n",
    "                                 max_depth = space['max_depth'],\n",
    "                                 learning_rate = space['learning_rate'],\n",
    "                                 colsample_bytree = space['colsample_bytree'],\n",
    "                                 )\n",
    "                )\n",
    "            ]\n",
    "        )\n",
    "    score = cross_val_score(model,  X_train, y_train, cv=5, scoring='r2').mean()\n",
    "    # We aim to maximize r2 score, therefore we return it as a negative value\n",
    "    return {'loss': -score, 'status': STATUS_OK }\n",
    "def optimize_xgb(trial):\n",
    "    space = {\n",
    "        'n_estimators':hp.uniformint('n_estimators',10,500),\n",
    "        'max_depth':hp.uniformint('max_depth',3,20),\n",
    "        'learning_rate':hp.uniform('learning_rate',0.01,0.5),\n",
    "        'colsample_bytree': hp.uniform('colsample_bytree',0.1, 1),\n",
    "    }\n",
    "    best = \\\n",
    "        fmin(\n",
    "            fn = objective_xgb,\n",
    "            space = space,\n",
    "            algo = tpe.suggest,\n",
    "            trials = trial,\n",
    "            max_evals = 200,\n",
    "            rstate = np.random.default_rng(seed)\n",
    "            )\n",
    "    return best\n",
    "\n",
    "XGB_optimizations = {}\n",
    "for mode in prediction_params.columns:\n",
    "    y = prediction_params[mode].dropna()\n",
    "    X = inputs.loc[y.index].dropna()\n",
    "    y = y.loc[X.index]\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=seed)\n",
    "    X_train_val, X_val, y_train_val, y_val = train_test_split(X_train, y_train, test_size=0.2, random_state=seed)\n",
    "    trial2=Trials()\n",
    "    XGB_optimizations[mode]=optimize_xgb(trial2)\n",
    "    print(XGB_optimizations[mode])\n",
    "pd.DataFrame(XGB_optimizations).to_csv(hyperopt_folder + \"xgb_optimizations.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trial2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100%|██████████| 100/100 [18:21:11<00:00, 660.71s/trial, best loss: -0.27741474985943826]     \n",
      "{'max_depth': 10.0, 'min_samples_leaf': 5.0, 'min_samples_split': 4.0, 'n_estimators': 240.0}\n",
      "100%|██████████| 100/100 [2:32:47<00:00, 91.67s/trial, best loss: -0.5377900707780396]  \n",
      "{'max_depth': 11.0, 'min_samples_leaf': 5.0, 'min_samples_split': 4.0, 'n_estimators': 237.0}\n",
      "100%|██████████| 100/100 [3:05:15<00:00, 111.15s/trial, best loss: -0.3795480834467947]  \n",
      "{'max_depth': 18.0, 'min_samples_leaf': 5.0, 'min_samples_split': 3.0, 'n_estimators': 358.0}\n",
      " 17%|█▋        | 17/100 [38:40<4:54:59, 213.25s/trial, best loss: -0.5295727808740887]"
     ]
    }
   ],
   "source": [
    "from hyperopt import hp,fmin,tpe,STATUS_OK,Trials\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.model_selection import cross_val_score\n",
    "seed = 2\n",
    "\n",
    "def objective_rf(space):\n",
    "    model = Pipeline(\n",
    "            steps=[\n",
    "                ('preprocessing_angles', AngleTransformer(angles = ['winddirection', 'yaw'])),\n",
    "                ('regressor', RandomForestRegressor(\n",
    "                                 n_estimators = space['n_estimators'],\n",
    "                                 max_depth = space['max_depth'],\n",
    "                                 min_samples_leaf = space['min_samples_leaf'],\n",
    "                                 min_samples_split = space['min_samples_split']\n",
    "                                 )\n",
    "            )\n",
    "        ]\n",
    "    )\n",
    "    score = cross_val_score(model,  X_train, y_train, cv=5, scoring='r2').mean()\n",
    "    # We aim to maximize r2 score, therefore we return it as a negative value\n",
    "    return {'loss': -score, 'status': STATUS_OK }\n",
    "\n",
    "def optimize_rf(trial):\n",
    "    space = {\n",
    "        'n_estimators': hp.uniformint('n_estimators',10,500),\n",
    "        'max_depth': hp.uniformint('max_depth',3,20),\n",
    "        'min_samples_leaf': hp.uniformint('min_samples_leaf',1,5),\n",
    "        'min_samples_split': hp.uniformint('min_samples_split',2,6)\n",
    "    }\n",
    "    best = \\\n",
    "        fmin(\n",
    "            fn = objective_rf,\n",
    "            space = space,\n",
    "            algo = tpe.suggest,\n",
    "            trials = trial,\n",
    "            max_evals = 100,\n",
    "            rstate = np.random.default_rng(seed)\n",
    "            )\n",
    "    return best\n",
    "\n",
    "RF_optimizations = {}\n",
    "for mode in prediction_params.columns:\n",
    "    y = prediction_params[mode].dropna()\n",
    "    X = inputs.loc[y.index].dropna()\n",
    "    y = y.loc[X.index]\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=seed)\n",
    "    trial=Trials()\n",
    "    RF_optimizations[mode]=optimize_rf(trial)\n",
    "    print(RF_optimizations[mode])\n",
    "pd.DataFrame(RF_optimizations).to_csv(hyperopt_folder + \"rf_optimizations.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trial"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "soiltwin",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
